{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3348d173-e02a-46b4-949f-db13b754d4e4",
   "metadata": {},
   "source": [
    "<head>\n",
    "    <link rel=\"stylesheet\" type=\"text/css\" href=\"styles.css\">\n",
    "</head>\n",
    "\n",
    "---\n",
    "title: \"Pense como um Cientista de Dados\"\n",
    "subtitle: \"Modelos de Árvore e Otimização Bayesiana para Classificação Binária: Casos Práticos no Mundo dos Negócios\"\n",
    "author: \"Alvaro Costa\"\n",
    "date: \"setembro 2024\"\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3ac34a8-aec4-41af-9ace-7ea39b5f1f54",
   "metadata": {},
   "source": [
    "<div class=\"chapter-header\">\n",
    "  <div class=\"chapter-number\">1</div>\n",
    "  <div class=\"chapter-title\">Desvendando o Algoritmo Original</div>\n",
    "</div>\n",
    "\n",
    "Aqui, vamos mergulhar no algoritmo que deu origem a toda essa aventura. Sim, estamos falando daquele artigo com título complicado: \"Optimized Ensemble Learning Approach with Explainable AI for Improved Heart Disease Prediction\", publicado em junho de 2024. Embora não seja um assunto trivial, com um pouco de esforço e dedicação, você verá que é perfeitamente compreensível e, mais importante, aplicável a problemas reais de negócios.\n",
    "\n",
    "## Entendendo o Contexto\n",
    "O artigo aborda um problema altamente relevante: a previsão de doenças cardíacas usando aprendizado de máquina. Os autores propõem uma abordagem inovadora, que combina modelos de **ensemble** otimizados com técnicas de interpretabilidade, com o objetivo não apenas de melhorar a precisão, mas também de entender os fatores que mais influenciam as previsões. Ou seja, não basta saber se uma pessoa tem uma doença cardíaca, é fundamental entender o \"porquê\" por trás dessa previsão.\n",
    "\n",
    "E por que isso é importante? Porque, seja na saúde, nos negócios ou em qualquer outro contexto, as previsões baseadas em dados precisam ser confiáveis e explicáveis. E essa combinação de alta performance e interpretabilidade não só melhora os resultados, mas também garante confiança nas decisões, seja por parte de médicos, gestores ou clientes.\n",
    "\n",
    "## O Fluxo do Algoritmo\n",
    "Vamos entender, de forma simplificada, como o algoritmo dos autores funciona e qual o papel de cada etapa no processo.\n",
    "\n",
    "### 1. Coleta e Preparação dos Dados\n",
    "Tudo começa com a obtenção e preparação dos dados. No caso do artigo, os autores usaram dados clínicos sobre doenças cardíacas. Mas os princípios de tratamento de dados são aplicáveis a qualquer contexto de negócios. As etapas incluem:\n",
    "\n",
    "- **Tratamento de valores ausentes**: Dados faltantes podem comprometer a qualidade do modelo. Sejam substituídos pela média, moda ou outras técnicas, ou mesmo eliminados, isso precisa ser feito com cuidado.\n",
    "\n",
    "- **Codificação de variáveis categóricas**: Muitos modelos de aprendizado de máquina só funcionam com dados numéricos, então variáveis categóricas precisam ser transformadas, com técnicas como *One-Hot Encoding*.\n",
    "\n",
    "- **Normalização ou padronização**: Variáveis com escalas diferentes (como renda anual e idade) precisam ser ajustadas para facilitar o trabalho do algoritmo.\n",
    "\n",
    "- **Divisão dos dados**: Sempre dividimos os dados em treinamento e teste para garantir que possamos avaliar o modelo com dados que ele ainda não viu.\n",
    "\n",
    "- **Balanceamento de classes**: Quando as classes estão desbalanceadas (por exemplo, muito mais clientes inadimplentes do que adimplentes), técnicas como o `SMOTE` podem ser utilizadas para gerar amostras sintéticas da classe minoritária e garantir que o modelo seja treinado de forma equilibrada.\n",
    "\n",
    "### 2. Seleção dos Modelos de *Ensemble*\n",
    "Os autores do artigo optaram por três modelos de *ensemble*, que são conhecidos por sua robustez e capacidade de reduzir o risco de *overfitting*:\n",
    "\n",
    "- **Random Forest**: Um conjunto de várias árvores de decisão, construídas a partir de amostras aleatórias dos dados. Cada árvore contribui com uma previsão, e o modelo final toma uma \"decisão coletiva\". Isso reduz a variação e melhora a precisão.\n",
    "\n",
    "- **AdaBoost**: Este modelo ajusta várias iterações de classificadores simples, atribuindo mais peso aos exemplos mal classificados a cada nova rodada. Ele se \"adapta\" aos erros, ajustando-se para melhorar a precisão.\n",
    "\n",
    "- **XGBoost**: Uma implementação otimizada de *Gradient Boosting*, que se destaca pela eficiência e pelo desempenho elevado. É amplamente utilizado em competições de *machine learning* devido à sua capacidade de lidar com grandes volumes de dados e produzir previsões precisas.\n",
    "\n",
    "### 3. Otimização de Hiperparâmetros com Otimização Bayesiana\n",
    "A cereja do bolo nesta abordagem é a **Otimização Bayesiana**, que torna o processo de ajuste de hiperparâmetros mais inteligente. Em vez de usar o *grid search* tradicional, que testa várias combinações de parâmetros de forma exaustiva, a Otimização Bayesiana modela a função objetivo (neste caso, a AUC) e decide de forma eficiente quais conjuntos de parâmetros testar a seguir. Isso economiza tempo e recursos computacionais.\n",
    "\n",
    "### 4. Avaliação e Seleção do Modelo\n",
    "Depois que os modelos são otimizados, eles são avaliados em métricas como:\n",
    "\n",
    "- **AUC (Área Sob a Curva ROC)**: Mede a capacidade do modelo de distinguir entre classes positivas e negativas.\n",
    "\n",
    "- **F1-Score**: A média harmônica entre precisão e recall, usada principalmente quando os dados estão desbalanceados.\n",
    "\n",
    "- **Precisão e Recall**: Essas métricas medem a proporção de predições corretas e a capacidade do modelo de encontrar todas as instâncias da classe positiva.\n",
    "\n",
    "Os autores ajustaram o limiar de decisão (*threshold*) para otimizar as métricas de acordo com o contexto, um passo importante quando o equilíbrio entre precisão e recall é crucial.\n",
    "\n",
    "### 5. Interpretabilidade com Valores SHAP\n",
    "Uma vez escolhido o melhor modelo, os autores usaram os valores SHAP (*SHapley Additive ExPlanations*) para explicar as previsões. O SHAP nos ajuda a entender a importância de cada característica, atribuindo um valor específico para a contribuição de cada variável nas previsões do modelo.\n",
    "\n",
    "Por que isso é importante? Porque em muitos casos, como em diagnósticos médicos ou decisões empresariais, o \"porquê\" é tão importante quanto o resultado em si. Saber que uma variável como \"pressão arterial\" influenciou fortemente a decisão pode ser crucial para validar o resultado e tomar decisões informadas.\n",
    "\n",
    "<div class=\"page-break\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0eb7-a942-400d-8618-8b1ea2340d80",
   "metadata": {},
   "source": [
    "## Por Que Essa Abordagem É Importante?\n",
    "Esse tipo de abordagem, que combina precisão com interpretabilidade, é crucial em muitos contextos. Modelos eficientes são ótimos, mas se você não souber explicar suas decisões, pode perder a confiança de seus *stakeholders*. Isso é especialmente relevante em setores como saúde e finanças, onde a transparência é uma exigência.\n",
    "\n",
    "Além disso, o uso da **Otimização Bayesiana** ajuda a economizar tempo e recursos, ajustando os modelos de maneira eficiente e inteligente. Isso significa menos horas gastas testando combinações de hiperparâmetros e mais tempo para analisar e melhorar os resultados.\n",
    "\n",
    "## Adaptando para Outros Contextos\n",
    "Embora o foco do artigo seja a previsão de doenças cardíacas, os mesmos princípios podem ser aplicados em vários outros cenários de negócios:\n",
    "\n",
    "- **Análise de risco de crédito**: Prever a probabilidade de inadimplência de clientes.\n",
    "\n",
    "- **Detecção de fraudes**: Identificar transações suspeitas em tempo real.\n",
    "\n",
    "- **Previsão de *churn***: Antecipar quais clientes estão propensos a abandonar o serviço.\n",
    "\n",
    "- **Classificação de *leads***: Priorizar potenciais clientes com maior probabilidade de conversão.\n",
    "\n",
    "A estrutura do algoritmo permanece a mesma; o que muda são os dados e, possivelmente, algumas nuances no pré-processamento ou nas métricas de avaliação.\n",
    "\n",
    "## Um Vislumbre do Código\n",
    "Para ilustrar como isso se traduz em código **Python**, vamos dar uma olhada em um esboço simplificado da implementação:\n",
    "\n",
    "<div class=\"code-block\">\n",
    "\n",
    "```{python}\n",
    "# Importação das bibliotecas necessárias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from skopt import BayesSearchCV\n",
    "import shap\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Carregamento e preparação dos dados com as_frame=False\n",
    "data = fetch_openml(name='heart', version=1, as_frame=False)\n",
    "\n",
    "# Definir os nomes das colunas conforme documentação do dataset\n",
    "feature_names = [\n",
    "    \"age\", \"sex\", \"cp\", \"trestbps\", \"chol\", \"fbs\", \"restecg\", \"thalach\", \n",
    "    \"exang\", \"oldpeak\", \"slope\", \"ca\", \"thal\"\n",
    "]\n",
    "\n",
    "# Converta a matriz esparsa para uma matriz densa e crie o DataFrame\n",
    "X = pd.DataFrame(data.data.toarray(), columns=feature_names)  # Converte para DataFrame com os nomes corretos\n",
    "y = pd.Series(data.target)\n",
    "\n",
    "# Certifique-se de que a variável-alvo é binária (0 ou 1)\n",
    "y = np.where(y > 0, 1, 0)  # Converte todas as classes maiores que 0 para 1\n",
    "\n",
    "# Divisão em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Normalizar as variáveis numéricas\n",
    "# Ajuste para lidar com dados esparsos, com with_mean=False\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Definição do espaço de hiperparâmetros para o Random Forest\n",
    "param_space = {\n",
    "    'n_estimators': (10, 200),\n",
    "    'max_depth': (1, 20),\n",
    "    'min_samples_split': (2, 10)\n",
    "}\n",
    "\n",
    "# Otimização Bayesiana\n",
    "bayes_search = BayesSearchCV(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    param_space,\n",
    "    n_iter=100,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Ajuste do modelo\n",
    "bayes_search.fit(X_train, y_train)\n",
    "best_model = bayes_search.best_estimator_\n",
    "\n",
    "# Avaliação do modelo\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular a acurácia e exibir a matriz de confusão\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Acurácia: {accuracy:.4f}\")\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(cm)\n",
    "\n",
    "# Verifique se X_test é uma matriz densa\n",
    "X_test_dense = pd.DataFrame(X_test, columns=feature_names)\n",
    "\n",
    "# Interpretabilidade com SHAP\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_test_dense)\n",
    "\n",
    "# Pegando os valores SHAP apenas para a classe 1 (classe positiva)\n",
    "shap_values_class_1 = shap_values[:, :, 1]\n",
    "\n",
    "# Gerar o gráfico com os valores SHAP para a classe positiva\n",
    "shap.summary_plot(shap_values_class_1, X_test_dense, show=False)\n",
    "\n",
    "# Salvar o gráfico gerado em PNG\n",
    "#plt.savefig('shap_summary_plot.png', format='png', dpi=300)\n",
    "\n",
    "# Exibir o gráfico (se desejar vê-lo na tela também)\n",
    "plt.show()\n",
    "```\n",
    "</div><br>\n",
    "\n",
    "Aqui, aplicamos a Otimização Bayesiana para encontrar os melhores hiperparâmetros para um modelo de *Random Forest* e usamos o SHAP para interpretar suas previsões.\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://penseemdados.github.io/bayesian_optimization_algorithm_book/assets/images/shap_summary_plot_01-01.png\" alt=\"Figura 1.1: Interpretabilidade com SHAP\" style=\"width: 75%\"/>\n",
    "  <div style=\"font-style: italic; font-size: 0.95em;\">1.1: Figura 1.1: Interpretabilidade com SHAP.</div>\n",
    "</div><br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://penseemdados.github.io/bayesian_optimization_algorithm_book/assets/images/roc_curve_01-02.png\" alt=\"Figura 1.2: Curva ROC\" style=\"width: 75%\"/>\n",
    "  <div style=\"font-style: italic; font-size: 0.95em;\">1.2: Figura 1.2: Curva ROC.</div>\n",
    "</div><br>\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img src=\"https://penseemdados.github.io/bayesian_optimization_algorithm_book/assets/images/precisao_recall_curve_01-03.png\" alt=\"Figura 1.3: Curva Precisão - Recall\" style=\"width: 75%\"/>\n",
    "  <div style=\"font-style: italic; font-size: 0.95em;\">1.2: Figura 1.3: Curva Precisão - Recall.</div>\n",
    "</div><br>\n",
    "\n",
    "<div class=\"code-block\">\n",
    "\n",
    "```{python}\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Convertendo as probabilidades em classes binárias usando um threshold (por exemplo, 0.5)\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "# Cálculo da acurácia\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia: {accuracy:.4f}\")\n",
    "\n",
    "# Geração da matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(cm)\n",
    "```\n",
    "</div><br>\n",
    "\n",
    "<div class=\"code-block\">\n",
    "\n",
    "```{python}\n",
    "Acurácia: 0.8642\n",
    "Matriz de Confusão:\n",
    "[[39  6]\n",
    " [ 5 31]]\n",
    "```\n",
    "</div><br>\n",
    "\n",
    "<div class=\"page-break\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9017daa-8e96-42cd-8648-fe18dc3e71ff",
   "metadata": {},
   "source": [
    "## Comentando as Figuras e Resultados\n",
    "\n",
    "Para complementar nossa compreensão inicial, vamos dar uma olhada rápida nas figuras e nos resultados obtidos pelo modelo. Não se preocupe se alguns conceitos ainda não estiverem claros; nos próximos capítulos, iremos explorar cada um deles em detalhes.\n",
    "\n",
    "### Figura 1.1: Interpretabilidade com SHAP\n",
    "A **Figura 1.1** apresenta um gráfico de resumo dos valores SHAP, que nos permite visualizar a importância de cada característica no modelo. As cores e posições dos pontos fornecem *insights* sobre como cada variável afeta as previsões. Embora não entremos em detalhes agora, este gráfico é fundamental para entender a interpretabilidade do modelo, e iremos explorá-lo aprofundadamente mais adiante.\n",
    "\n",
    "### Figura 1.2: Curva ROC\n",
    "A **Figura 1.2** mostra a Curva ROC (*Receiver Operating Characteristic*) do nosso modelo. Esta curva é uma ferramenta poderosa para avaliar a capacidade do modelo em distinguir entre as classes positivas e negativas em diferentes limiares de decisão. A proximidade da curva ao canto superior esquerdo indica um desempenho robusto. Nos capítulos futuros, iremos dissecar esta curva para entender completamente o que ela revela sobre a performance do modelo.\n",
    "\n",
    "### Figura 1.3: Curva Precisão - Recall\n",
    "A **Figura 1.3** apresenta a Curva Precisão-Recall, que é especialmente útil quando lidamos com conjuntos de dados desbalanceados. Esta curva nos ajuda a encontrar o equilíbrio ideal entre precisão e recall, permitindo otimizar o modelo de acordo com as necessidades específicas do negócio. Fique tranquilo, iremos explorar como interpretar e utilizar esta curva nos próximos capítulos.\n",
    "\n",
    "### Resultados de Desempenho do Modelo\n",
    "Além das visualizações geradas com SHAP e as curvas de ROC e Precisão-Recall, obtivemos métricas quantitativas que ajudam a avaliar o desempenho do modelo:\n",
    "\n",
    "- **Acurácia**: 0.8642\n",
    "\n",
    "- **Matriz de Confusão**:\n",
    "\n",
    "<div class=\"code-block\">\n",
    "\n",
    "```{python}\n",
    "    [[ 39   6]\n",
    "     [  5 31]]\n",
    "```\n",
    "</div><br>\n",
    "\n",
    "A acurácia indica que nosso modelo está correto em aproximadamente 86% das previsões, o que é um resultado promissor. A matriz de confusão nos fornece uma visão detalhada das classificações verdadeiras e falsas para cada classe:\n",
    "\n",
    "- **Verdadeiros Positivos (TP)**: 39 casos em que o modelo previu positivamente e estava correto.\n",
    "\n",
    "- **Verdadeiros Negativos (TN)**: 30 casos em que o modelo previu negativamente e estava correto.\n",
    "\n",
    "- **Falsos Positivos (FP)**: 6 casos em que o modelo previu positivamente, mas estava incorreto.\n",
    "\n",
    "- **Falsos Negativos (FN)**: 5 casos em que o modelo previu negativamente, mas estava incorreto.\n",
    "\n",
    "Este balanço entre TP, TN, FP e FN é crucial para entender as implicações práticas do modelo, especialmente em contextos onde os custos de falsos positivos e falsos negativos são diferentes. No decorrer do livro, iremos analisar profundamente estes resultados para extrair *insights* valiosos e aprimorar ainda mais o modelo.\n",
    "\n",
    "Este é apenas um esboço para dar uma ideia geral. Nos próximos capítulos, vamos aprofundar cada etapa, adicionando detalhes e explicações para que você possa replicar e adaptar a abordagem ao seu contexto específico.\n",
    "\n",
    "Neste capítulo, exploramos em detalhes o algoritmo proposto pelos autores do artigo que inspirou nossa jornada. Entendemos como a combinação de modelos de *ensemble* otimizados e interpretabilidade através de valores SHAP pode criar soluções poderosas e aplicáveis a diversos problemas de negócios.\n",
    "\n",
    "A chave aqui é a adaptabilidade. Embora o caso de uso original seja a previsão de doenças cardíacas, os princípios e técnicas podem ser aplicados a uma ampla gama de desafios. Compreender o fluxo do algoritmo e os motivos por trás de cada etapa nos prepara para colocar tudo isso em prática.\n",
    "\n",
    "No próximo capítulo, vamos arregaçar as mangas e mergulhar no código. Vamos apresentar a implementação completa, explicando cada linha em detalhes para que você possa entender não apenas o \"como\", mas também o \"porquê\" de cada decisão.\n",
    "\n",
    "Prepare seu ambiente de desenvolvimento e até lá!\n",
    "\n",
    "<div class=\"page-break\"></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
